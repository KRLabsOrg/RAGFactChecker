import logging
from typing import List

from langchain_core.messages import BaseMessage

from rag_fact_checker.data import HallucinationDataGeneratorOutput, Config
from rag_fact_checker.model.hallucination_data_generator import (
    HallucinationDataGenerator,
)
from rag_fact_checker.pipeline import PipelineDemonstration


class LLMMultiShotHallucinationDataGenerator(
    HallucinationDataGenerator, PipelineDemonstration
):
    """
    This class contains hallucination pipelines to generate hallucination data.
        The hallucination dataset looks like:
                "generated_hlcntn_answer": some hallucinated answer

        Methods:

        __init__(self, config: Config, logger: logging.Logger)
            Initializes the data generator with the given configuration.

        get_model_prompt(self, reference_documents, question, **kwargs)
            Generates a model prompt for hallucinated data generation.

        hlcntn_prompt_input_formatter(self, reference_documents, question)
            Formats the input for the hallucination prompt.

        generate_hlcntn_data(self, reference_text: str, question: str)
            Generates hallucination data from reference_text, question.

        parse_hlcntn_data_generation_output(self, hlcntn_data_generation_output)
            Parses the output from the hallucinated data generation.

    """

    def __init__(self, config: Config, logger: logging.Logger):
        HallucinationDataGenerator.__init__(self, config, logger)
        PipelineDemonstration.__init__(self, config)

    def get_model_prompt(
        self, reference_documents: list, question: str, **kwargs
    ) -> List[BaseMessage]:
        """
        Generates a model prompt based on the provided reference documents and question.

        Args:
            reference_documents (list of str): A list of documents to be used as references for generating the prompt.
            question (str): The question for which the prompt is being generated.
            **kwargs: Additional keyword arguments that may be used by the method.

        Returns:
            str: The generated model prompt.
        """
        return self.message_list_template[
            "n_shot_hallucinated_data_generation_test"
        ].invoke(
            input=self.hlcntn_prompt_input_formatter(reference_documents, question)
        )

    def hlcntn_prompt_input_formatter(
        self, reference_documents: list, question: str
    ) -> dict[str, str]:
        """
        Formats the input for the hallucination prompt.

        Args:
            reference_documents (list of str): A list of reference documents to be included in the prompt.
            question (str): The question to be included in the prompt.

        Returns:
            dict: A dictionary containing the formatted prompt input with the following keys:
                - "reference_documents" (str): Reference documents joined by newline and hyphen.
                - "question" (str): The question to be included in the prompt.
                - "examples" (list): A list of example data generated by the `get_demo_data_by_idx` method.
        """

        result = {
            "reference_documents": "\n- ".join(reference_documents),
            "question": question,
            "examples": self.get_demo_data(
                demo_type="hallucination_data_generator",
            ),
        }
        return result

    def generate_hlcntn_data(
        self, reference_text: str, question: str
    ) -> HallucinationDataGeneratorOutput:
        """
        Generates hallucination data from the original dataset using a triplet generator.

        Args:
            original_dataset (dict): The original dataset containing reference documents and questions.
            triplet_generator (object): An object capable of generating triplets from answers.

        Returns:
            HallucinationDataGeneratorOutput
            Attributes:
                - "generated_hlcntn_answer" (str): The generated hallucinated answer.
                - "generated_non_hlcntn_answer" (str): The generated non-hallucinated answer.
                - "hlcntn_part" (str): The hallucinated details.
        """
        hlcntn_generation_prompt = self.get_model_prompt(
            reference_documents=reference_text,
            question=question,
        )
        hlcntn_data_generation_output = self.model.invoke(
            hlcntn_generation_prompt
        ).content

        generated_non_hlcntn_answer, generated_hlcntn_answer, hlcntn_part = (
            self.parse_hlcntn_data_generation_output(hlcntn_data_generation_output)
        )

        return HallucinationDataGeneratorOutput(
            **{
                "generated_non_hlcntn_answer": generated_non_hlcntn_answer,
                "generated_hlcntn_answer": generated_hlcntn_answer,
                "hlcntn_part": hlcntn_part,
            }
        )

    def parse_hlcntn_data_generation_output(
        self, hlcntn_data_generation_output: str
    ) -> str:
        """
        Parses the hallucination data generation output and extracts the non-hallucinated answer,
        hallucinated answer, and hallucinated details.

        Args:
            hlcntn_data_generation_output (str): The output string from the hallucination data generation process.

        Returns:
            tuple: A tuple containing:
                - non_hlcntn_answer (str): The non-hallucinated answer extracted from the output.
                - hlcntn_answer (str): The hallucinated answer extracted from the output.
                - hlcntn_part (str): The hallucinated details extracted from the output.
        """
        answer_part = hlcntn_data_generation_output.split("Hallucinated Details:")[0]
        hlcntn_part = hlcntn_data_generation_output.split("Hallucinated Details:")[1]
        hlcntn_answer = answer_part.split("Hallucinated Answer:\n")[2].replace("*", "")
        non_hlcntn_answer = answer_part.split("Hallucinated Answer:\n")[1].replace(
            "Non-Hallucinated Answer:\n", ""
        )
        return non_hlcntn_answer, hlcntn_answer, hlcntn_part
